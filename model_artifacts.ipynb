{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b46a6b4-8701-4f5f-b519-bf16425b126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing data...\n",
      "Final data shape for training: (800, 32)\n",
      "Scaling features...\n",
      "Training Diabetes model...\n",
      "Training HBP model...\n",
      "Saving artifacts...\n",
      "Artifacts saved successfully in 'model_artifacts' directory.\n"
     ]
    }
   ],
   "source": [
    "# --- save_artifacts.py ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib \n",
    "import os\n",
    "\n",
    "# Define the directory to save artifacts\n",
    "ARTIFACTS_DIR = 'model_artifacts' \n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True) # Create directory if it doesn't exist\n",
    "\n",
    "print(\"Loading data...\")\n",
    "# --- IMPORTANT: Use the *exact* same dataset as in your final notebook ---\n",
    "data = pd.read_excel(r\"C:\\Users\\ASUS\\Downloads\\V5_Capstone_Final_Dataset.xlsx\") \n",
    "\n",
    "print(\"Preprocessing data...\")\n",
    "# --- Apply the *exact* same preprocessing ---\n",
    "data['Year'] = data['REF_DATE']\n",
    "# Handle potential division by zero or missing population data\n",
    "data['Actual Population'] = data['Actual Population'].replace(0, np.nan) # Replace 0 with NaN\n",
    "data.dropna(subset=['Actual Population'], inplace=True) # Drop rows where population is missing\n",
    "data['Diabetes_per_capita'] = (data['Diabetes'] / data['Actual Population']) * 1000\n",
    "data['HBP_per_capita'] = (data['High Blood Pressure'] / data['Actual Population']) * 1000\n",
    "# Handle potential infinite values if Diabetes/HBP were non-zero but population was NaN/0 before drop\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(subset=['Diabetes_per_capita', 'HBP_per_capita'], inplace=True)\n",
    "\n",
    "\n",
    "# Define selected features - MUST MATCH THE ORDER USED FOR TRAINING/SCALING\n",
    "selected_features = [\n",
    "    'Sugar and confectionery', 'Eggs', 'Bakery products', 'Butter', \n",
    "    'Dairy products', 'Cheese', 'Fresh vegetables', \n",
    "    'Preserved fruit and fruit preparations', 'Fish', \n",
    "    'Non-alcoholic beverages', 'Preserved vegetables and vegetable preparations', \n",
    "    'Actual Population', 'Year' \n",
    "]\n",
    "# Ensure no NaN/inf values remain in selected features or target vars before training\n",
    "data.dropna(subset=selected_features + ['Diabetes_per_capita', 'HBP_per_capita'], inplace=True)\n",
    "\n",
    "\n",
    "print(f\"Final data shape for training: {data.shape}\")\n",
    "if data.empty:\n",
    "    raise ValueError(\"Data is empty after preprocessing and NaN removal. Check your data and preprocessing steps.\")\n",
    "\n",
    "\n",
    "X = data[selected_features]\n",
    "y_diabetes = data['Diabetes_per_capita']\n",
    "y_hbp = data['HBP_per_capita']\n",
    "\n",
    "print(\"Scaling features...\")\n",
    "# Fit the scaler ONCE on the full data (or training split if you had one)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X) # Fit the scaler\n",
    "\n",
    "print(\"Training Diabetes model...\")\n",
    "# --- Use your FINAL chosen parameters --- \n",
    "# Example using parameters from Code 1 initially, but ideally use tuned ones\n",
    "model_d = XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=6, random_state=42) \n",
    "# model_d = XGBRegressor(**best_params_from_gridsearch_d) # Or use tuned params\n",
    "model_d.fit(scaler.transform(X), y_diabetes) # Train on scaled data\n",
    "\n",
    "print(\"Training HBP model...\")\n",
    "# --- Use your FINAL chosen parameters ---\n",
    "model_hbp = XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "# model_hbp = XGBRegressor(**best_params_from_gridsearch_hbp) # Or use tuned params\n",
    "model_hbp.fit(scaler.transform(X), y_hbp) # Train on scaled data\n",
    "\n",
    "print(\"Saving artifacts...\")\n",
    "# Save the models, scaler, and feature list\n",
    "joblib.dump(model_d, os.path.join(ARTIFACTS_DIR, 'diabetes_model.joblib'))\n",
    "joblib.dump(model_hbp, os.path.join(ARTIFACTS_DIR, 'hbp_model.joblib'))\n",
    "joblib.dump(scaler, os.path.join(ARTIFACTS_DIR, 'scaler.joblib'))\n",
    "joblib.dump(selected_features, os.path.join(ARTIFACTS_DIR, 'selected_features.pkl'))\n",
    "\n",
    "print(f\"Artifacts saved successfully in '{ARTIFACTS_DIR}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8c04c-9dae-4546-b42d-0185092989f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
